{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic: Machine Learning from Disaster\n### [https://www.kaggle.com/c/titanic/overview](http://)\n\n**The purpose of this notebook is to demonstrate the implementation of different ensembling algorithms on sklearn**\n\n### Initially the classifiers below were used for training:\n\n* Random Forest Classifier \n* Extra Trees Classifier \n* K Neighbors Classifier \n* Support Vector Classification \n* Ridge Classifier \n\n\n1. Bagging Classifier - Then, above classifiers were used as a base estimator in bagging ensemble\n\n2. Voting Classifier - in the next part, combination of the above models were used as estimators in the voting classifier (hard voting)\n\n3. XGboost - Finally, XGboost ensemble was used seperately for training\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train.csv', 'gender_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sklearn\nimport re\nimport xgboost as xgb\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier,BaggingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import RidgeClassifier\nfrom sklearn.model_selection import cross_val_score","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nPassengerId = test['PassengerId']","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if there are any missing values\ntrain['Has_Cabin'] = ~train[\"Cabin\"].isnull()\ntest['Has_Cabin'] = ~test[\"Cabin\"].isnull()","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_data = [train, test]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create new feature FamilySize as a combination of SibSp and Parch\nfor dataset in full_data:\n    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n# Create new feature IsAlone from FamilySize\nfor dataset in full_data:\n    dataset['IsAlone'] = 0\n    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n# Remove all NULLS in the Embarked column\nfor dataset in full_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n# Remove all NULLS in the Fare column and create a new feature CategoricalFare\nfor dataset in full_data:\n    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\ntrain['CategoricalFare'] = pd.qcut(train['Fare'], 4)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a New feature CategoricalAge\nfor dataset in full_data:\n    age_avg = dataset['Age'].mean()\n    age_std = dataset['Age'].std()\n    age_null_count = dataset['Age'].isnull().sum()\n    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n    dataset['Age'] = dataset['Age'].astype(int)\ntrain['CategoricalAge'] = pd.cut(train['Age'], 5)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Group all non-common titles into one single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')# Define function to extract titles from passenger names\ndef get_title(name):\n    title_search = re.search(' ([A-Za-z]+)\\.', name)\n    # If the title exists, extract and return it.\n    if title_search:\n        return title_search.group(1)\n    return \"\"\n# Create a new feature Title, containing the titles of passenger names\nfor dataset in full_data:\n    dataset['Title'] = dataset['Name'].apply(get_title)\n# Group all non-common titles into one single grouping \"Rare\"\nfor dataset in full_data:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dataset in full_data:\n    # Mapping Sex\n    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n    \n    # Mapping titles\n    title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)\n    \n    # Mapping Embarked\n    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n    \n    # Mapping Fare\n    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n    dataset['Fare'] = dataset['Fare'].astype(int)\n    \n    # Mapping Age\n    dataset.loc[ dataset['Age'] <= 16, 'Age']  = 0\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4 ;","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_elements = ['Name', 'Ticket', 'Cabin', 'SibSp']\ntrain = train.drop(drop_elements, axis = 1)\ntest  = test.drop(drop_elements, axis = 1)\ntrain = train.drop(['CategoricalAge', 'CategoricalFare'], axis = 1)\n\nX_train = train.drop(labels = ['Survived'], axis=1).set_index('PassengerId')\ny_train = train.set_index('PassengerId')['Survived']\nX_test = test.set_index('PassengerId')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"             Pclass  Sex  Age  ...    FamilySize  IsAlone  Title\nPassengerId                    ...                              \n1                 3    1    1  ...             2        0      1\n2                 1    0    2  ...             2        0      3\n3                 3    0    1  ...             1        1      2\n4                 1    0    2  ...             2        0      3\n5                 3    1    2  ...             1        1      1\n\n[5 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Has_Cabin</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n      <th>Title</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>True</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.head()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"             Pclass  Sex  Age  ...    FamilySize  IsAlone  Title\nPassengerId                    ...                              \n892               3    1    2  ...             1        1      1\n893               3    0    2  ...             2        0      3\n894               2    1    3  ...             1        1      1\n895               3    1    1  ...             1        1      1\n896               3    0    1  ...             3        0      3\n\n[5 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>Parch</th>\n      <th>Fare</th>\n      <th>Embarked</th>\n      <th>Has_Cabin</th>\n      <th>FamilySize</th>\n      <th>IsAlone</th>\n      <th>Title</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":13,"outputs":[{"output_type":"stream","text":"(891, 10)\n(418, 10)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 1. Random Forest Classifier\n\n### Random Forest Classifier - Simple\n\nResult on Kaggle test: % **77.51**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(rf.score(X_train, y_train)*100))\n# cv score for Random Forest Classifier\ncv_scores = cross_val_score(rf, X_train, y_train, cv=10, n_jobs=-1)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(rf.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = rf.predict(X_test)","execution_count":14,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 89.79\nMean of: 0.810, std: (+/-) 0.037 [RandomForestClassifier]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Classifier as base estimator for Bagging Classifier\nResult on Kaggle test: % **77.51**"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\nrf_bag = BaggingClassifier(rf, max_samples=0.4, max_features=10)\nrf_bag.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(rf_bag.score(X_train, y_train)*100))\n\n## cv_score for rf_bag\nbagging_scores = cross_val_score(rf_bag, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n                       .format(rf_bag.__class__.__name__, \n                        bagging_scores.mean(), bagging_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = rf_bag.predict(X_test)","execution_count":15,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 87.43\nMean of: 0.814, std: (+/-) 0.040 [Bagging BaggingClassifier]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 2. Extra Trees Classifier\n\n### Extra Trees Classifier - Simple\n\nResult on Kaggle test: % **75.59**"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreesClassifier()\net.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(et.score(X_train, y_train)*100))\n# cv score for Random Forest Classifier\ncv_scores = cross_val_score(et, X_train, y_train, cv=10, n_jobs=-1)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(et.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = et.predict(X_test)\n","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 89.90\nMean of: 0.805, std: (+/-) 0.037 [ExtraTreesClassifier]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Extra Trees Classifier as base estimator for Bagging Classifier\nResult on Kaggle test: % **75.59**"},{"metadata":{"trusted":true},"cell_type":"code","source":"et = ExtraTreesClassifier()\net_bag = BaggingClassifier(et, max_samples=0.4, max_features=10)\net_bag.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(et_bag.score(X_train, y_train)*100))\n\n## cv_score for rf_bag\nbagging_scores = cross_val_score(et_bag, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n                       .format(et_bag.__class__.__name__, \n                        bagging_scores.mean(), bagging_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = et_bag.predict(X_test)","execution_count":17,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 87.99\nMean of: 0.810, std: (+/-) 0.030 [Bagging BaggingClassifier]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 3. K Neighbors Classifier\n\n### K Neighbors Classifier - Simple\n\nResult on Kaggle test: % ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(knn.score(X_train, y_train)*100))\n# cv score \ncv_scores = cross_val_score(knn, X_train, y_train, cv=10, n_jobs=-1)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(knn.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = knn.predict(X_test)\n","execution_count":18,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 84.85\nMean of: 0.786, std: (+/-) 0.048 [KNeighborsClassifier]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### K Neighbors Classifier as base estimator for Bagging Classifier\nResult on Kaggle test: % **76.07**"},{"metadata":{"trusted":true},"cell_type":"code","source":"knn = KNeighborsClassifier()\nknn_bag = BaggingClassifier(knn, max_samples=0.4, max_features=10)\nknn_bag.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(knn_bag.score(X_train, y_train)*100))\n\n## cv_score for rf_bag\nbagging_scores = cross_val_score(knn_bag, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n                       .format(knn_bag.__class__.__name__, \n                        bagging_scores.mean(), bagging_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = knn_bag.predict(X_test)","execution_count":19,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 83.73\nMean of: 0.818, std: (+/-) 0.024 [Bagging BaggingClassifier]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 4. Support Vector Classification\n\n### Support Vector Classification - Simple\n\nResult on Kaggle test: % ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(svc.score(X_train, y_train)*100))\n# cv score \ncv_scores = cross_val_score(svc, X_train, y_train, cv=10, n_jobs=-1)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(svc.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = svc.predict(X_test)\n","execution_count":20,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 83.50\nMean of: 0.829, std: (+/-) 0.031 [SVC]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Support Vector Classification as base estimator for Bagging Classifier\nResult on Kaggle test: % ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"svc = SVC()\nsvc_bag = BaggingClassifier(knn, max_samples=0.4, max_features=10)\nsvc_bag.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(svc_bag.score(X_train, y_train)*100))\n\n## cv_score for rf_bag\nbagging_scores = cross_val_score(svc_bag, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n                       .format(svc_bag.__class__.__name__, \n                        bagging_scores.mean(), bagging_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = svc_bag.predict(X_test)","execution_count":21,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 84.40\nMean of: 0.813, std: (+/-) 0.035 [Bagging BaggingClassifier]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# 5. Ridge Classifier\n\n### Ridge Classifier - Simple\n\nResult on Kaggle test: % ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"rg = RidgeClassifier()\n\nrg.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(rg.score(X_train, y_train)*100))\n# cv score \ncv_scores = cross_val_score(rg, X_train, y_train, cv=10, n_jobs=-1)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(rg.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = rg.predict(X_test)\n","execution_count":22,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 81.03\nMean of: 0.806, std: (+/-) 0.026 [RidgeClassifier]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Ridge Classifier as base estimator for Bagging Classifier\nResult on Kaggle test: % ****"},{"metadata":{"trusted":true},"cell_type":"code","source":"rg = RidgeClassifier()\nrg_bag = BaggingClassifier(rg, max_samples=0.4, max_features=10)\nrg_bag.fit(X_train, y_train)\nprint(\"Accuracy on train data: % {:.2f}\".format(rg_bag.score(X_train, y_train)*100))\n\n## cv_score for rf_bag\nbagging_scores = cross_val_score(rg_bag, X_train, y_train, cv=10, n_jobs=-1)\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\"\n                       .format(rg_bag.__class__.__name__, \n                        bagging_scores.mean(), bagging_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = rg_bag.predict(X_test)","execution_count":23,"outputs":[{"output_type":"stream","text":"Accuracy on train data: % 81.03\nMean of: 0.807, std: (+/-) 0.029 [Bagging BaggingClassifier]\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Voting Classifier\nSoft Voting/Majority Rule classifier for unfitted estimators.\nhttps://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n\n### 1. Voting Ensemble of simple models"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier()\net = ExtraTreesClassifier()\nknn = KNeighborsClassifier()\nsvc = SVC()\nrg = RidgeClassifier()","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), ('KNeighbors', knn), ('SVC', svc), ('Ridge Classifier', rg)], voting='hard')\nfor clf, label in zip([rf, et, knn, svc, rg, eclf], ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', 'Ridge Classifier', 'Ensemble']):\n    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))","execution_count":25,"outputs":[{"output_type":"stream","text":"Accuracy: 0.80 (+/- 0.04) [Random Forest]\nAccuracy: 0.81 (+/- 0.04) [Extra Trees]\nAccuracy: 0.79 (+/- 0.05) [KNeighbors]\nAccuracy: 0.83 (+/- 0.03) [SVC]\nAccuracy: 0.81 (+/- 0.03) [Ridge Classifier]\nAccuracy: 0.82 (+/- 0.04) [Ensemble]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2. Voting Ensemble of bagging models\n\nKaggle test result: % **77.51** "},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = [rf_bag, et_bag, knn_bag, svc_bag, rg_bag]\neclf = VotingClassifier(estimators=[('Random Forests Bag', rf_bag), ('Extra Trees Bag', et_bag), ('KNeighbors Bag', knn_bag), ('SVC Bag', svc_bag), ('Ridge Classifier Bag', rg_bag)], voting='hard')\nfor clf, label in zip([rf_bag, et_bag, knn_bag, svc_bag, rg_bag ,eclf], ['Random Forest Bag', 'Extra Trees Bag', 'KNeighbors Bag', 'SVC Bag', 'Ridge Classifier Bag', 'Ensemble Bag']):\n    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n","execution_count":26,"outputs":[{"output_type":"stream","text":"Accuracy: 0.81 (+/- 0.04) [Random Forest Bag]\nAccuracy: 0.81 (+/- 0.04) [Extra Trees Bag]\nAccuracy: 0.82 (+/- 0.03) [KNeighbors Bag]\nAccuracy: 0.82 (+/- 0.03) [SVC Bag]\nAccuracy: 0.80 (+/- 0.03) [Ridge Classifier Bag]\nAccuracy: 0.82 (+/- 0.03) [Ensemble Bag]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict and create submission\neclf = VotingClassifier(estimators=[('Random Forests Bag', rf_bag), ('Extra Trees Bag', et_bag), ('KNeighbors Bag', knn_bag), ('SVC Bag', svc_bag), ('Ridge Classifier Bag', rg_bag)], voting='hard')\neclf.fit(X_train, y_train)\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = eclf.predict(X_test)","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XGboost\n\nKaggle test result: % **78.46** **"},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'max_depth': 2, 'eta': 1, 'silent': 1, 'objective': 'binary:logistic'}\n\n\ndtrain = xgb.DMatrix(X_train, label=y_train)\nxg = xgb.train(param, dtrain, 10)\ndtest = xgb.DMatrix(X_test)\nxgbpreds = xg.predict(dtest)\nxgbpreds = xgbpreds > 0.5\nxgbpreds = xgbpreds.astype(int)\n\nprint(\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\"  \n                   .format(xg.__class__.__name__, \n                   cv_scores.mean(), cv_scores.std()))\n\nsubmission_df = pd.read_csv(\"../input/gender_submission.csv\",index_col=0)\nsubmission_df['Survived'] = xgbpreds","execution_count":28,"outputs":[{"output_type":"stream","text":"Mean of: 0.806, std: (+/-) 0.026 [Booster]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n# create a random sample dataframe\ndf = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))\n\n# create a link to download the dataframe\ncreate_download_link(submission_df, filename = \"titanic.csv\")\n\n# ↓ ↓ ↓  Yay, download link! ↓ ↓ ↓ ","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<a download=\"titanic.csv\" href=\"data:text/csv;base64,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\" target=\"_blank\">Download CSV file</a>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}